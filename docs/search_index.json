[["index.html", "Introducción a la estadística agrícola en R Un manual básico de R, apoyado de teorías básicas de la estadística con ejemplos aplicados a la agricultura. Chapter 1 Conceptos básicos 1.1 Población (N) 1.2 Muestra (n) 1.3 Unidad elemental 1.4 Variable 1.5 Observación 1.6 Parámetro 1.7 Estadístico 1.8 Deficinión de Estadística 1.9 División de la Estadística", " Introducción a la estadística agrícola en R Un manual básico de R, apoyado de teorías básicas de la estadística con ejemplos aplicados a la agricultura. Vásquez V., C.R.A. 09 Mayo, 2022 Chapter 1 Conceptos básicos 1.1 Población (N) Es el conjunto de todos los elementos que se desean analizar y que presentan una o varias características en común. Ejemplos: Las parcelas de maíz amarillo duro en la comunidad de Lambayeque durante los meses de abril a agosto de 2021. Las plantas de arándano variedad Biloxi en el área experimental del vivero, modulo 9. 1.2 Muestra (n) Es un subconjunto representativo de elementos provenientes de una problación. Ejemplos: Las parcelas de 10 agricultores de maíz amarillo duro en la comunidad de Lambayeque. 30 plantas de arándano variedad Biloxi en el área experimental del vivero, modulo 9. 1.3 Unidad elemental Es cada una de las personas, animales, cosas, o entidades que conforman las población en estudio. Ejemplos: Las parcelas de maíz amarillo duro. Las plantas de arándano. 1.4 Variable Es toda característica que se desea observar, medir o evaluar de las unidades elementales. Las variables se pueden clasificar en cuantitativas o cualitativas. 1.4.1 Variable cualitativa Proporcionan datos que dan como resultado una categoría. Pueden ser de tipo nominal u ordinal. 1.4.1.1 Nominales Son aquellos cuyos valores o resultados pueden ser organizados y presentados en cualquier orden. Ejemplos: Forma de la hoja bandera del maíz. Tipo de dentadura del grano de maíz. 1.4.1.2 Ordinales Son aquellas cuyos valores o resultados deben ser organizados y presentados en orden definido. Ejemplos: Grado de instrucción del agricultor. 1.4.2 Variable cuantitativa Son aquellas cuyos valores pueden ser expresados en forma numérica, Pueden ser discretas o continuas. 1.4.2.1 Discreta Son aquellas que tienen un número finito o infinito numerable de valores posibles. Por lo general se obtienen mediante conteo. Ejemplo: Número de hojas por planta. 1.4.2.2 Continua Son aquellas que tienen una cantidad infinita o no numerable de valores posibles. Por lo general se puede obtener mediante instrumentos de medición. Ejemplos: Diámetro de fruto. Peso de fruto. 1.4.3 Otra forma de clasificación de variables Otra forma de clasificación de las varibales es según su escalada de medida. De esta manera la clasificación sería: Nominal: Los datos son etiquetas o nombres que se emplean para definir un atributo del elemento. Ejemplos: Estado civil, profesión, género. Ordinal: Los datos son etiquetas y además se pueden ordenar de forma ascendente o descendente. Ejemplos: Nivel de apreciación o calidad de un fruto. Intervalo: Los datos son numéricos, el cero es relativo, es decir, no indica ausencia de la característica medida. Ejemplo: Temperatura, fechas del calendario. Razón: Los datos son numéricos, el cero es absoluto, es decir, indica la ausencia de característica medida. Ejemplo: Peso, estatura, salario, diámetro. 1.5 Observación Es el dato registrado, producto de la medición o aprecación de una característica en una unidad elemental. Ejemplo: El ingreso mensual de la empresa agroexportadora Camposol, producto de las ventas de arándano. 1.6 Parámetro Es una medida que resume los datos provenientes de la población. Es decir es una función de todas las observaciones de una población. Ejemplo: Luego de realizar un censo a los agricultores del distrito de Túcume se obtuvo que el ingreso medio mensual fue de 920 soles. 1.7 Estadístico Es una medida que resume los datos provenientes de la muestra. Ejemplo: Luego de realizar un muestreo a 30 agricultores del distrito de Túcume se obtuvo que el ingreso medio mensual fue de 950 soles. 1.8 Deficinión de Estadística Es la ciencia que se ocupa de la creación, desarrollo y aplicación de técnicas que permiten hacer un análisis confiable de una población. En terminos generales, se ocupa de la colección, resumen, presentación, análisis e interpretación de datos y resultados, de modo tal que pueda evaluarse la confiabilidad y riesgos asociados a las conclusiones que se puedan derivar a partir de los datos captados. 1.9 División de la Estadística 1.9.1 Descriptiva Son técnicas de recolección, caracterización, resumen y presentación que permiten describir un conjunto de datos. Con un análisis descriptivo, se pueden obtener indicadores (estimaciones puntuales). tablas de frecuencia (o contingencia) y gráficos. Para realizar el análisis descriptivo se debe tener en cuenta el tipo de variable que se está analizando (cualitativa o cuantitativa) y la cantidad de variables que se están analizando a la vez (univariada, bivariada o multivariada). 1.9.2 Inferencial Son técnicas para estimar parámetros de una población o tomar decisiones sobre la población basadas en el resultado de una muestra. Estas conclusiones pueden tener cierto margen de error; por eso, se dan con una medida de confiabilidad o probabilidad. Comprende la estimación de intervalos de confianza y la realización de pruebas de hipótesis para uno o varios parámetros. Al igual que el análisis descriptivo para realizar un inferencial se debe tener en cuenta la naturaleza de la variable (si los datos provienen de alguna distribución teórica), el tipo de variable y la cantidad de variables involucradas en el análisis. 1.9.3 Paramétrica Utiliza cálculos y procedimientos asumiendo que conoce cómo se distribuye la variable aleatoria a estudiar. 1.9.4 No paramétrica No requiere del conocimiento de la distribución de la variable aleatoria a estudiar. "],["indicadores-estadísticos.html", "Chapter 2 Indicadores estadísticos 2.1 Importancia de los indicadores 2.2 Indicadores de centralidad 2.3 Indicadores de dispersión 2.4 Indicadores de la forma de los datos", " Chapter 2 Indicadores estadísticos 2.1 Importancia de los indicadores Los indicadores son utilizados para expresar en forma resumida su comportamiento, de tal manera que nos permita decidir sobre su estado y poder comparar con otros similares. 2.2 Indicadores de centralidad Promedio. Es el punto central de valores continuos y es representativo cuando no se tiene valores extremos. \\[\\text{Promedio = }\\sum_{i=1}^n \\frac{x_i}{n}\\] Para ilustración se utilizará el inventario de maíz en la localidad 2. Loc2 &lt;- maiz2[maiz2$Localidad==&quot;L2&quot;,] cat(&quot;Promedio de la longitud de grano en la Localidad 2:&quot;,mean(Loc2$LG, na.rm = TRUE), &quot;mm.\\n&quot;) Promedio de la longitud de grano en la Localidad 2: 12.13244 mm. El promedio de longitud de grano en la localidad 2 fue de 12.13244 mm. Mediana. Una medida robusta de centralidad, útil cuando hay valores extremos (outliers), su uso frecuente es en variables de tipo ordinal o de escala de jerarquía. El valor es obtenido después de ordenar los datos y obtener el punto que divide al conjunto de datos en dos partes iguales. Si \\(X_i\\) son los valores ordenados del conjunto, y \\(n\\) es el número de datos, entonces la mediana es calculada como; \\[\\text{Mediana} = \\left \\{ \\begin{array}{ll} (X_{n/2}+X_{n/2+1})/2 &amp; \\text{si n es par}\\\\ (X_{(n+1)/2}) &amp; \\text{si n es impar} \\end{array} \\right.\\] Para ilustración se utilizará el inventario de maíz en la localidad 2. cat(&quot;Mediana de la longitud de grano en la Localidad 2:&quot;,median(Loc2$LG, na.rm = TRUE), &quot;mm.\\n&quot;) Mediana de la longitud de grano en la Localidad 2: 12.205 mm. El valor que divide a las observaciones de la longitud de grano en la Localidad 2 en dos partes iguales fue de 12.205 mm. También se puede decir que, el valor máximo obtenido por el 50 % de observaciones con menor valor de longitud de grano en la Localidad 2 fue de 12.205 mm. Moda. Es el valor más expresivo del conjunto, en datos cualitativos, es el más abundante. Si hay dos, se indica una población bimodal. No es frecuente en datos discretos y mucho menos en continuos. Sin embargo, es posible obtener la moda en datos continuos, después de agruparlos. \\[\\text{Moda = Valor más frecuente del conjunto}\\] longitud &lt;- Loc2$LG x &lt;- sort(longitud) n &lt;- length(x) h &lt;- graph.freq(x,plot=FALSE) moda &lt;- stat.freq(h)$mode[1,3] cat(&quot;Moda de la longitud de grano en la Localidad 2:&quot;,round(moda,2),&quot;mm.\\n&quot;) Moda de la longitud de grano en la Localidad 2: 12.09 mm. El valor más frecuente de la longitud de grano en la Localidad 2 fue de 12.09 mm. 2.3 Indicadores de dispersión Rango. Es la diferencia de los valores extremos (máximo y mínimo) de los datos. Útil cuando se tiene menos de 10 observaciones. \\[\\text{Rango = max(x)-min(x)}\\] # range(x) # diff(range(x)) # rango &lt;- max(x)-min(x); rango cat(&quot;Rango de la longitud de grano en la Localidad 2:&quot;,diff(range(x)),&quot;mm.\\n&quot;) Rango de la longitud de grano en la Localidad 2: 6.19 mm. La diferencia entre el valor máximo y el valor mínimo de la longitud de grano observada en la Localidad 2 fue de 6.19 mm. Desviación estándar (S). Medida de variación obtenida frecuentemente de una muestra de más de 10 observaciones. \\[S= \\sqrt {\\sum_{i=1}^n \\frac{(x_i-\\bar{x})^2}{n-1}}\\] cat(&quot;Desviación estándar de la longitud de grano en la Localidad 2:&quot;,sd(x),&quot;mm.\\n&quot;) Desviación estándar de la longitud de grano en la Localidad 2: 1.018199 mm. La media de la longitud de grano en la localidad 2, se dispersa o varía en + o - 1.02 mm. Varianza o Variancia (\\(S^2\\)). Medida de variación obtenida frecuentemente de una muestra de más de 10 datos. \\[S^2 = \\sum_{i=1}^n \\frac{(x_i-\\bar{x})^2}{n-1}\\] cat(&quot;Variancia de la longitud de grano en la Localidad 2:&quot;,var(x),&quot;mm^2.\\n&quot;) Variancia de la longitud de grano en la Localidad 2: 1.036729 mm^2. La variancia de la longitud de grano en la localidad 2 fue de 1.03 \\(mm^2\\). Eso indica que la suma de los errores o residuos al cuadrado sobre n-1 fue de 1.03 mm^2. Covarianza o Covariancia. Es la medida de variación conjunta que tiene dos variables aleatorias. En el caso de medidas alométricas, es útil la covariaza para medir la variación conjunta entre la altura y diámetro de los árboles. Es una medida recomendada con muestras de más de diez observaciones. \\[cov(x,y) = \\sum_{i=1}^n \\frac{(x_i-\\bar{x})(y_i-\\bar{y})}{n-1} \\] # X &lt;- Loc2[,5:6] X &lt;- Loc2[,c(5,6)] V &lt;- var(X,na.rm = TRUE) cat(&quot;Covariancia de la longitud y el ancho de grano en la Localidad 2:&quot;,V[2,1],&quot;.\\n&quot;) Covariancia de la longitud y el ancho de grano en la Localidad 2: 0.03575264 . La variación conjunta de la longitud de grano con el ancho de grano en la localidad 2 fue de 0.0357, por lo tanto, existe una relación positiva entre la longitud de grano y el ancho de grano. Rango intercuartil (IQR): Medida de variación apropiada cuando hay valores extremos con fines de comparar con otros grupos. Se calcula como la diferencia entre los cuartiles 3 y 1. \\[IQR = Q_3-Q_1\\] cat(&quot;IQR de la longitud de grano en la Localidad 2:&quot;,IQR(x,na.rm = TRUE),&quot;.\\n&quot;) IQR de la longitud de grano en la Localidad 2: 1.32 . El rango intercuartil es 1.32, lo que significa que, como la mediana fue de 12.205 mm, entonces el \\(50\\%\\) de mazorcas evaluadas de maíz está dispersa entre 12.865 y 11.545 mm. Aproximadamente su variación sería de \\(5.40\\%\\). Coeficiente de variación (CV). Es una medida de variación relativa, útil para comparar la variación de medidas con diferentes unidades. \\[CV= \\frac{S*100}{\\bar{x}}\\] cv &lt;- function(x){ mean = mean(x) sd = sd(x) cv = sd/mean*100 return(cv) } cv &lt;- sd(x)/mean(x)*100 cat(&quot;Coeficiente de variación de la longitud de grano en la Localidad 2:&quot;,raster::cv(x,na.rm = TRUE),&quot;%.\\n&quot;) Coeficiente de variación de la longitud de grano en la Localidad 2: 8.392368 %. Si el CV es menor igual a 30 %, la dispersión de los datos es homogénea. Si el CV es mayor a 30 % la dispersión de los datos es heterogénea. El CV no debe ser utilizado como una medida de confiabilidad de los datos en inferencia estadística. La medida de variación de la longitud de grano en la localidad 2 fue de \\(8.39\\%\\), por lo cual, la desviación de los datos con respecto a la media fue homogénea o baja (normal). 2.4 Indicadores de la forma de los datos Se entiende por la asimetría que puedan presentar. Asimetría positiva, cuando se evidencia una tendencia de la cola de los datos hacia la derecha. También llamada asimetría a la derecha. Asimetría negativa, cuando se evidencia una cola o tendencia de los datos hacia la izquierda. También llamada asimetría a la izquierda. Simetría, presenta una sola moda y no hay tendencia marcada, el punto medio sirve de refereicnai para expresar la tendencia de los datos. En terminos cuantitativos, se calcula para establecer criterios de considerar asimétría o simetría. Cuando el valor de la asimetría está cercano a cero, se indica población simétrica, los valores podrían ser en terminos absolutos menos de 1. Superior a este valor, se considera asimétrica, y según el signo, este será asimétrica positiva o negativa. El análisis es gráfico y cuantitativo. El gráfico de asimetría se observa en la densidad de frecuencia o histograma de frecuencia. El valor esta relacionado al promedio y la mediana. cat(&quot;Coeficiente de simetría de la longitud de grano en la Localidad 2:&quot;,skewness(x),&quot;.\\n&quot;) Coeficiente de simetría de la longitud de grano en la Localidad 2: -0.4577135 . El valor de simetría es lejano a 0, por lo tanto, la forma de los datos en la longitud de grano de la localiidad 2 no es simétrico. Existe asimetría negativa por tener un coeficiente de simetría de -0.46. Gráficamente se observa su forma de la longitud de grano. Es necesario utilizar el histograma en la escala de densidad. Usar la función graph.freq() de agricolae. h &lt;- graph.freq(x,frequency = 3) polygon.freq(h,col=&quot;red&quot;,lwd=2,frequency = 3) lines(density(x),col=&quot;blue&quot;) h &lt;- graph.freq(x, frequency = 3, border=&quot;white&quot;) polygon.freq(h,col=&quot;red&quot;,lwd=2,frequency = 3) lines(density(x),col=&quot;blue&quot;) Se observa una mayor expresión en el histograma de agricolae con el polígono de frecuencia que la densidad. Tallos y Hojas Es otra manera de expresar la forma de los datos, es frecuentemente utilizado con pocos datos, porque el proceso es manual. En R se tiene la función stem() que utiliza este procedimiento. stem(x) The decimal point is at the | 8 | 4 8 | 78 9 | 0 9 | 5688 10 | 001112234 10 | 5556677889999 11 | 000000011111122222222223333333334444444444 11 | 55555555555666666666666667777777777778888888888888999999 12 | 00000000000000011111111111222222233333333333333333333333334444444444 12 | 5555555556666666777777777778888888889999999999 13 | 000000000001111111111122222222333333444444 13 | 55555556777788999 14 | 000012233 14 | 56 Cada dato es expresado en el gráfico con su valor real, si son muchos, será representado por un caracter, para visualizar la forma. En el ejemplo presentado, se observa que la longitud de grano en la localidad 1 tienen una distrubición asimétrica negativa. "],["análisis-exploratorio-y-descriptivo.html", "Chapter 3 Análisis exploratorio y descriptivo 3.1 Caso: Investigación en Maíz 3.2 Resumen general de los datos 3.3 Pigmentación Antociánica de los estigmas 3.4 Exploración y estadísticas de la localidad 1 3.5 Exploración y estadísticas de los tratamientos en Maíz", " Chapter 3 Análisis exploratorio y descriptivo 3.1 Caso: Investigación en Maíz Se realizó un estudio del comportamiento agronómico de líneas promisorias y variedades comerciales de maíz amarillo duro en un experimento ubicado en el distrito de Picsi, Provincia de Ferreñafe, Departamento de Lambayeque, Perú. op &lt;- par(mar = c(3,12,2,2), cex = 0.8) cat(&quot;Información del inventario:\\n&quot;) Información del inventario: # Estructura del data.frame str(maiz) tibble [640 x 6] (S3: tbl_df/tbl/data.frame) $ Tratamiento: chr [1:640] &quot;T1&quot; &quot;T1&quot; &quot;T1&quot; &quot;T1&quot; ... $ Localidad : chr [1:640] &quot;L1&quot; &quot;L1&quot; &quot;L1&quot; &quot;L1&quot; ... $ PAE : Ord.factor w/ 5 levels &quot;Ausente o muy débil&quot;&lt;..: 4 4 4 3 3 3 3 3 4 4 ... $ LG : num [1:640] 12.4 13.4 12.6 12.5 12.3 ... $ AG : num [1:640] 10.32 9.69 10.13 9.32 9.27 ... $ PM : num [1:640] 220 192 231 175 223 ... cat(&quot;Clase del inventario:\\n&quot;) Clase del inventario: # Clase class(maiz) [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; cat(&quot;Primeros registros:\\n&quot;) Primeros registros: # Resumen de la base de datos head(maiz,10) # A tibble: 10 x 6 Tratamiento Localidad PAE LG AG PM &lt;chr&gt; &lt;chr&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 T1 L1 Fuerte 12.4 10.3 220. 2 T1 L1 Fuerte 13.4 9.69 192. 3 T1 L1 Fuerte 12.6 10.1 231. 4 T1 L1 Media 12.5 9.32 175 5 T1 L1 Media 12.3 9.27 223. 6 T1 L1 Media 12.7 9.24 181. 7 T1 L1 Media 12.6 9.27 185. 8 T1 L1 Media 13 9.35 232. 9 T1 L1 Fuerte 12.9 10.0 236. 10 T1 L1 Fuerte 13.5 10.3 123 cat(&quot;Número de columnas:\\n&quot;) Número de columnas: # Ncol ncol(maiz) [1] 6 cat(&quot;Número de filas:\\n&quot;) Número de filas: # Nrow nrow(maiz) [1] 640 cat(&quot;Dimensiones:\\n&quot;) Dimensiones: # Dimensiones dim(maiz) [1] 640 6 # Tabla de frecuencia cat(&quot;Total de observaciones:&quot;,nrow(maiz),&quot;\\n&quot;) Total de observaciones: 640 cat(&quot;Tabla de frecuencia de los tratamientos:\\n&quot;) Tabla de frecuencia de los tratamientos: table(maiz$Tratamiento) -&gt; tabla1 tabla1 T1 T2 T3 T4 T5 T6 T7 T8 80 80 80 80 80 80 80 80 barplot(tabla1, horiz = FALSE, las = 1) cat(&quot;Tabla de frecuencia de las localidades:\\n&quot;) Tabla de frecuencia de las localidades: table(maiz$Localidad) -&gt; tabla2 tabla2 L1 L2 320 320 barplot(tabla2, horiz = TRUE, las = 1) par(op) 3.2 Resumen general de los datos summary(maiz) Tratamiento Localidad PAE LG AG PM Length:640 Length:640 Ausente o muy débil:139 Min. : 8.37 Min. : 5.740 Min. : 22.1 Class :character Class :character Débil :254 1st Qu.:11.80 1st Qu.: 8.268 1st Qu.:192.2 Mode :character Mode :character Media :144 Median :12.41 Median : 8.855 Median :226.7 Fuerte :103 Mean :12.45 Mean : 8.828 Mean :224.6 Muy fuerte : 0 3rd Qu.:13.16 3rd Qu.: 9.393 3rd Qu.:256.7 Max. :16.62 Max. :12.780 Max. :358.4 3.3 Pigmentación Antociánica de los estigmas op &lt;- par(mar = c(3,12,2,2), cex = 0.8) cat(&quot;Tabla de frecuencia de PAE:\\n&quot;) Tabla de frecuencia de PAE: table(maiz$PAE) -&gt; tabla3 addmargins(tabla3) Ausente o muy débil Débil Media Fuerte Muy fuerte Sum 139 254 144 103 0 640 barplot(tabla3,horiz = TRUE, las = 1) cat(&quot;Tabla de proporciones de PAE:\\n&quot;) Tabla de proporciones de PAE: addmargins(prop.table(tabla3)) Ausente o muy débil Débil Media Fuerte Muy fuerte Sum 0.2171875 0.3968750 0.2250000 0.1609375 0.0000000 1.0000000 cat(&quot;Tabla de frecuencia y proporciones de PAE:\\n&quot;) Tabla de frecuencia y proporciones de PAE: cbind(addmargins(tabla3),addmargins(prop.table(tabla3))) [,1] [,2] Ausente o muy débil 139 0.2171875 Débil 254 0.3968750 Media 144 0.2250000 Fuerte 103 0.1609375 Muy fuerte 0 0.0000000 Sum 640 1.0000000 # Otras formas cat(&quot;Tabla de frecuencia y proporciones de PAE:\\n&quot;) Tabla de frecuencia y proporciones de PAE: summarytools::freq(maiz$PAE, plain.ascii = FALSE, style = &quot;rmarkdown&quot;) ### Frequencies #### maiz$PAE **Type:** Ordered Factor | &amp;nbsp; | Freq | % Valid | % Valid Cum. | % Total | % Total Cum. | |------------------------:|-----:|--------:|-------------:|--------:|-------------:| | **Ausente o muy débil** | 139 | 21.72 | 21.72 | 21.72 | 21.72 | | **Débil** | 254 | 39.69 | 61.41 | 39.69 | 61.41 | | **Media** | 144 | 22.50 | 83.91 | 22.50 | 83.91 | | **Fuerte** | 103 | 16.09 | 100.00 | 16.09 | 100.00 | | **Muy fuerte** | 0 | 0.00 | 100.00 | 0.00 | 100.00 | | **\\&lt;NA\\&gt;** | 0 | | | 0.00 | 100.00 | | **Total** | 640 | 100.00 | 100.00 | 100.00 | 100.00 | cat(&quot;Tabla de frecuencia y proporciones de PAE:\\n&quot;) Tabla de frecuencia y proporciones de PAE: summarytools::freq(maiz$PAE, plain.ascii = FALSE, style = &quot;rmarkdown&quot;, cumul = FALSE, headings = FALSE, report.nas = FALSE) | &amp;nbsp; | Freq | % | |------------------------:|-----:|-------:| | **Ausente o muy débil** | 139 | 21.72 | | **Débil** | 254 | 39.69 | | **Media** | 144 | 22.50 | | **Fuerte** | 103 | 16.09 | | **Muy fuerte** | 0 | 0.00 | | **Total** | 640 | 100.00 | cat(&quot;Tabla de frecuencia y proporciones de PAE:\\n&quot;) Tabla de frecuencia y proporciones de PAE: summarytools::freq(maiz$PAE, plain.ascii = FALSE, style = &quot;rmarkdown&quot;, cumul = TRUE, headings = FALSE, report.nas = FALSE) | &amp;nbsp; | Freq | % | % Cum. | |------------------------:|-----:|-------:|-------:| | **Ausente o muy débil** | 139 | 21.72 | 21.72 | | **Débil** | 254 | 39.69 | 61.41 | | **Media** | 144 | 22.50 | 83.91 | | **Fuerte** | 103 | 16.09 | 100.00 | | **Muy fuerte** | 0 | 0.00 | 100.00 | | **Total** | 640 | 100.00 | 100.00 | p1 &lt;- round(prop.table(tabla3)*100,2) pie(p1, main = &quot;Gráfico circular&quot;) pie(p1, main = &quot;Gráfico circular&quot;, labels = c(&quot;Ausente o muy\\ndébil (21.71 %)&quot;,&quot;Débil (39.69 %)&quot;,&quot;Media (22.5 %)&quot;,&quot;Fuerte (16.09 %)&quot;,&quot;Muy fuerte\\n(0 %)&quot;)) barplot(tabla3,horiz = TRUE, las = 1, main = &quot;Gráfico de barras&quot;, col = &quot;blue&quot;) barplot(prop.table(tabla3)*100,horiz = TRUE, las = 1) cat(&quot;Tabla de contingencia de PAE según los tratamientos:\\n&quot;) Tabla de contingencia de PAE según los tratamientos: table(maiz$PAE,maiz$Tratamiento) -&gt; tabla4 addmargins(tabla4) T1 T2 T3 T4 T5 T6 T7 T8 Sum Ausente o muy débil 0 20 0 1 71 44 2 1 139 Débil 0 34 66 0 7 36 55 56 254 Media 45 20 14 17 2 0 23 23 144 Fuerte 35 6 0 62 0 0 0 0 103 Muy fuerte 0 0 0 0 0 0 0 0 0 Sum 80 80 80 80 80 80 80 80 640 cat(&quot;Margenes de fila:\\n&quot;) Margenes de fila: margin.table(tabla4,1) Ausente o muy débil Débil Media Fuerte Muy fuerte 139 254 144 103 0 cat(&quot;Margenes de columna:\\n&quot;) Margenes de columna: margin.table(tabla4,2) T1 T2 T3 T4 T5 T6 T7 T8 80 80 80 80 80 80 80 80 barplot(tabla4,horiz = TRUE, las = 1, main = &quot;Gráfico de barras&quot;) cat(&quot;Tabla de contingencia (Proporciones) de PAE según los tratamientos:\\n&quot;) Tabla de contingencia (Proporciones) de PAE según los tratamientos: cat(&quot;Tabla de contingencia de PAE según la localidad:\\n&quot;) Tabla de contingencia de PAE según la localidad: table(maiz$PAE,maiz$Localidad) -&gt; tabla5 tabla5 L1 L2 Ausente o muy débil 65 74 Débil 127 127 Media 81 63 Fuerte 47 56 Muy fuerte 0 0 barplot(tabla5,horiz = TRUE, las = 1, main = &quot;Gráfico de barras&quot;, beside = T) par(op) 3.4 Exploración y estadísticas de la localidad 1 Loc1 &lt;- subset(maiz, maiz$Localidad==&quot;L1&quot;) summary(Loc1[,c(3,4,5,6)]) PAE LG AG PM Ausente o muy débil: 65 Min. : 9.60 Min. : 6.800 Min. : 22.1 Débil :127 1st Qu.:12.15 1st Qu.: 8.475 1st Qu.:199.5 Media : 81 Median :12.74 Median : 9.000 Median :231.3 Fuerte : 47 Mean :12.76 Mean : 9.005 Mean :228.7 Muy fuerte : 0 3rd Qu.:13.40 3rd Qu.: 9.482 3rd Qu.:256.8 Max. :16.62 Max. :12.120 Max. :356.1 # summary(Loc1[,3:6]) Diagrama de Tukey (diagrama de cajas, box plot) op &lt;- par(mar = c(4,3,2,2), cex = 0.8) LGLoc1 &lt;- with(Loc1, boxplot(LG, col = &quot;Yellow&quot;, main = &quot;Longitud de grano&quot;)) LGLoc1 $stats [,1] [1,] 10.44 [2,] 12.15 [3,] 12.74 [4,] 13.41 [5,] 15.07 $n [1] 320 $conf [,1] [1,] 12.62871 [2,] 12.85129 $out [1] 15.50 16.62 10.00 9.90 9.92 9.60 9.83 $group [1] 1 1 1 1 1 1 1 $names [1] &quot;&quot; AGLoc1 &lt;- with(Loc1, boxplot(AG, col = &quot;Orange&quot;, main = &quot;Ancho de grano&quot;)) AGLoc1 $stats [,1] [1,] 7.010 [2,] 8.470 [3,] 9.000 [4,] 9.485 [5,] 11.000 $n [1] 320 $conf [,1] [1,] 8.91035 [2,] 9.08965 $out [1] 11.01 6.80 6.90 11.78 11.01 6.85 6.88 11.19 12.12 $group [1] 1 1 1 1 1 1 1 1 1 $names [1] &quot;&quot; 3.5 Exploración y estadísticas de los tratamientos en Maíz Estadísticas promedios &lt;- with(maiz, tapply.stat(maiz[,4:6],Tratamiento,function(x) mean(x,na.rm = TRUE))) promedios Tratamiento LG AG PM 1 T1 12.27925 9.236750 214.4975 2 T2 12.41137 8.915375 214.7250 3 T3 11.63850 8.380625 192.0925 4 T4 12.24137 9.232125 248.9787 5 T5 12.96575 7.834375 222.0712 6 T6 12.02725 9.709500 209.6138 7 T7 12.58475 8.583500 247.0175 8 T8 13.42400 8.731375 248.0725 sd &lt;- with(maiz, tapply.stat(maiz[,4:6],Tratamiento,function(x) sd(x,na.rm = TRUE))) sd Tratamiento LG AG PM 1 T1 0.8252024 0.7796474 48.15737 2 T2 1.0147367 0.6724392 40.80827 3 T3 1.0458418 0.6713492 52.99939 4 T4 0.7469698 0.6477198 34.69407 5 T5 0.8486173 0.7227722 39.96212 6 T6 1.0328270 0.9407900 43.59886 7 T7 0.9791264 0.7983133 51.69534 8 T8 0.7943433 0.5543493 47.92838 Diagrama de Tukey para el ancho de grano de los tratamientos op &lt;- par(mar = c(10,2,2,2), cex = 0.8) ancho &lt;- with(maiz, boxplot(AG ~ Tratamiento, col = &quot;Green&quot;, main = &quot;Diagrama de ancho de grano por tratamiento&quot;, las = 2, xlab = &quot;&quot;)) par(op) Diagrama de Tukey para el longitud de grano de los tratamientos op &lt;- par(mar = c(10,2,2,2), cex = 0.8) longitud &lt;- with(maiz, boxplot(LG ~ Tratamiento, col = &quot;Red&quot;, main = &quot;Diagrama de longitud de grano por tratamiento&quot;, las = 2, xlab = &quot;&quot;)) par(op) Tabla de frecuencia y gráfico de líneas para Número de hileras por mazorca # Variable cuantitativa discreta # Tabla de frecuencias f1 &lt;- table(maiz2$HPP) p2 &lt;- round(prop.table(f1)*100,2) # La función que permite unir vectores tabla6 &lt;- cbind(f1,p2) tabla6 f1 p2 2 1 0.16 8 1 0.16 10 2 0.31 12 45 7.03 14 209 32.66 15 2 0.31 16 194 30.31 17 1 0.16 18 128 20.00 19 2 0.31 20 44 6.88 22 11 1.72 # Gráfico de líneas x &lt;- row.names(tabla6) graphics::plot(p2, type = &quot;h&quot;,col = 3,main = &quot;Gráfico de líneas&quot;,las = 2) Tabla de frecuencia y gráfico de líneas para Longitud de grano # Variable cuantitativa continua # Tabla de frecuencias h2 &lt;- with(maiz2, graph.freq(LG,plot = TRUE)) print(table.freq(h2), row.names = FALSE) Lower Upper Main Frequency Percentage CF CPF 8.0 8.9 8.45 3 0.5 3 0.5 8.9 9.8 9.35 5 0.8 8 1.2 9.8 10.7 10.25 24 3.8 32 5.0 10.7 11.6 11.15 84 13.1 116 18.1 11.6 12.5 12.05 229 35.8 345 53.9 12.5 13.4 12.95 180 28.1 525 82.0 13.4 14.3 13.85 92 14.4 617 96.4 14.3 15.2 14.75 21 3.3 638 99.7 15.2 16.1 15.65 1 0.2 639 99.8 16.1 17.0 16.55 1 0.2 640 100.0 # Grafico h &lt;- hist(maiz2$LG) polygon.freq(h) psych::multi.hist(maiz2[,5:7],global = F) psych::histBy(as.data.frame(maiz2),&quot;LG&quot;,&quot;Tratamiento&quot;) psych::histBy(LG~Localidad,data=as.data.frame(maiz2)) tapply(maiz2$LG, maiz2$Localidad,mean) L1 L2 12.76062 12.13244 Resumen general de un dataset psych::describe(maiz2) vars n mean sd median trimmed mad min max range skew kurtosis se Tratamiento* 1 640 4.50 2.29 4.50 4.50 2.97 1.00 8.00 7.00 0.00 -1.24 0.09 Localidad* 2 640 1.50 0.50 1.50 1.50 0.74 1.00 2.00 1.00 0.00 -2.00 0.02 HPP 3 640 15.80 2.34 16.00 15.71 2.97 2.00 22.00 20.00 0.02 1.54 0.09 GPM 4 640 32.95 5.35 33.00 32.92 5.93 2.00 49.00 47.00 -0.22 1.05 0.21 LG 5 640 12.45 1.05 12.41 12.47 0.97 8.37 16.62 8.25 -0.26 0.90 0.04 AG 6 640 8.83 0.91 8.86 8.83 0.82 5.74 12.78 7.04 0.13 0.88 0.04 PM 7 640 224.63 49.27 226.70 225.62 47.29 22.10 358.40 336.30 -0.23 0.22 1.95 PAE* 8 640 2.33 0.99 2.00 2.29 1.48 1.00 4.00 3.00 0.30 -0.93 0.04 summarytools::descr(maiz2) Non-numerical variable(s) ignored: Tratamiento, Localidad, PAE Descriptive Statistics maiz2 N: 640 AG GPM HPP LG PM ----------------- -------- -------- -------- -------- -------- Mean 8.83 32.95 15.80 12.45 224.63 Std.Dev 0.91 5.35 2.34 1.05 49.27 Min 5.74 2.00 2.00 8.37 22.10 Q1 8.27 29.00 14.00 11.80 192.15 Median 8.86 33.00 16.00 12.41 226.70 Q3 9.39 37.00 18.00 13.16 256.70 Max 12.78 49.00 22.00 16.62 358.40 MAD 0.82 5.93 2.97 0.97 47.29 IQR 1.12 8.00 4.00 1.36 64.47 CV 0.10 0.16 0.15 0.08 0.22 Skewness 0.13 -0.22 0.02 -0.26 -0.23 SE.Skewness 0.10 0.10 0.10 0.10 0.10 Kurtosis 0.88 1.05 1.54 0.90 0.22 N.Valid 640.00 640.00 640.00 640.00 640.00 Pct.Valid 100.00 100.00 100.00 100.00 100.00 "],["análisis-exploratorio-y-descriptivo-ii.html", "Chapter 4 Análisis exploratorio y descriptivo II 4.1 Escala de medida 4.2 Aplicación", " Chapter 4 Análisis exploratorio y descriptivo II 4.1 Escala de medida Es una manera de valorar los datos observados desde los datos cuantitativos o datos cualitativos. 4.1.1 Escala nominal Corresponde a valores de tipo cualitativo, sin ningún orden y por lo general son pocos los niveles o valores. No se puede realizar operaciones elementales, solo permite conteo. 4.1.2 Escala ordinal Las clases o categorías que se asigna a los observado de tipo cualitativo, mantiene una cierta jerarquía sin importar su distanciamiento y son conocidos como variables seudo cuantitativas. 4.1.3 Escala de intervalo. Es aplicable en datos cuantitativos, no permiten todas las operaciones elementales, solo suma o resta. 4.1.4 Escala de razón Es aplicable por lo general a datos cuantitativos continuos generados por instrumentos de medida. 4.2 Aplicación Para establecer la identificación y diferencias en las medidas, se utilizará el investario de maíz. Se registró información de variables morfológicas del maíz en dos localidades y ocho tratamientos. Tratamiento T1 T2 T3 T4 T5 T6 T7 T8 52 49 43 51 55 54 42 54 Localidad L1 L2 188 212 PAE Ausente o muy débil Débil Media Fuerte Muy fuerte 93 152 85 70 0 La descripción permite indicar lo siguiente: Escala nominal Tratamiento Localidad Escala ordinal Pigmentación antociánica de los estigmas (PAE). Escala de intervalo No se registran variables en escala intervalo. Escala de razon Hojas por planta (HPP). Granos por mazorca (GPM). Longitud de grano (LG). Ancho de grano (AG). Peso de mazorca (PM). Su identificación de algunas medias, permite agrupar, y son considerados como factores. Tratamiento Localidad Pigmentación antociánica de los estigmas (PAE). 4.2.1 Medidas estadísticas Para el ejemplo, utilizar la moda como medida expresiva (representativa) para las variables Localidad y Tratamiento. En la variable PAE, que es ordinal, la medida más relevante y expresiva es la mediana. 4.2.2 Representación de las medidas en gráficos. Es importante caracterizar el tipo de medida en su escala definida. Distribución de los tratamientos op &lt;- par(mar = c(4,10,2,2)) tratamientos &lt;- table(maiz3$Tratamiento) barplot(tratamientos, horiz = FALSE, density = 15, col = &quot;blue&quot;, las = 2) par(op) op &lt;- par(mar = c(0,0,0,0)) pie(tratamientos) par(op) En el caso de la escala ordinal, debe tener presente el orden (ascendente o descendente). op &lt;- par(mar = c(4,4,2,2)) PAE &lt;- table(maiz3$PAE) barplot(PAE, horiz = TRUE, density = 15, col = &quot;blue&quot;, las = 2) par(op) En el caso de variable discreta en datos agrupados, el gráfico debe ser de líneas verticales para cada valor. Para este caso simulamos datos de un comportamiento binomial, como número de frutos de mango defectuosos en 30 cajas de 5 unidades observadas cada una (probabilidad de éxito de 0.3) op &lt;- par(mar = c(4,4,2,2)) x &lt;- rbinom(30,5,0.3) y &lt;- table(x) plot(y) points(as.numeric(names(y)),y,pch=20,cex = 2) par(op) En el caso de variables continuas que corresponden a la escala de razón, los, los histogramas, diagramas de cajas y puntos son las más utilizadas. Para mostrar estos gráficos se utilizará la longitud y el ancho de los granos en el inventario muestreado. op &lt;- par(mar = c(4,4,2,2)) Localidad1 &lt;- subset(maiz3,maiz3$Localidad==&quot;L1&quot;) pairs(Localidad1[,c(5,6)]) par(op) Se observa que la relación entre LG y AG es muy débil, no existe un patrón que indique una relación fuerte entre las variables LG y AG. Los histogramas y el diagráma de cajas (Tukey) permite una mejor descripción. op &lt;- par(mar = c(4,4,2,2)) h1 &lt;- hist(Localidad1$LG, main = &quot;Longitud de grano en la localidad 1&quot;) h2 &lt;- hist(Localidad1$AG, main = &quot;Ancho de grano en la localidad 1&quot;) par(op) Diagráma de cajas para la Longitud de grano y el ancho de grano de todos los tratamientos op &lt;- par(mar = c(4,4,2,2)) b1 &lt;- boxplot(LG ~ Tratamiento, data = Localidad1, xlab = &quot;&quot;, main = &quot;Longitud de grano en la localidad 1&quot;) b2 &lt;- boxplot(AG ~ Tratamiento, data = Localidad1, xlab = &quot;&quot;, main = &quot;Ancho de grano en la localidad 1&quot;) par(op) "],["pruebas-de-hipótesis.html", "Chapter 5 Pruebas de hipótesis 5.1 Prueba sobre la media poblacional 5.2 Prueba de una cola superior 5.3 Prueba de una cola inferior 5.4 Limites de confianza 5.5 Prueba de dos colas", " Chapter 5 Pruebas de hipótesis 5.1 Prueba sobre la media poblacional La media poblacional es un parámetro que mide la centralidad de los datos. Lo que se investiga a través de la hipótesis, es probar si hay cambios en la medida central. T1 &lt;- maiz2[maiz2$Tratamiento==&quot;T1&quot;,] T2 &lt;- maiz2[maiz2$Tratamiento==&quot;T2&quot;,] T3 &lt;- maiz2[maiz2$Tratamiento==&quot;T3&quot;,] 5.2 Prueba de una cola superior El interés del investigador es probar que la media del Longitud de grano es superior a la actual. Prueba la hipótesis que la media de LG del tratamiento 1 es superior a 15 mm. \\(H_0: \\mu \\le 15~mm\\) \\(H_1: \\mu &gt; 15~mm\\) \\(\\alpha = 0.05\\) Utilice la prueba de t-student t.test(T1$LG, mu = 15, alternative = &quot;greater&quot;) One Sample t-test data: T1$LG t = -29.49, df = 79, p-value = 1 alternative hypothesis: true mean is greater than 15 95 percent confidence interval: 12.12569 Inf sample estimates: mean of x 12.27925 # Valor critico de la prueba qt(0.95,79) [1] 1.664371 Se observó que la media de la longitud de grano en el tratamiento 1 fue de 12.28 mm. Conclusión, con un alfa de 0.05, existe suficiente evidencia estadística para no rechazar la \\(H_0\\) (hipótesis nula), por lo tanto, se concluye que la media de la longitud de grano en el tratamiento 1 es menor o igual a 15 mm. No hay ninguna evidencia estadística para sospechar que la media de LG en el tratamiento 1 sea mayor o superior a 15 mm, debido a que el pvalor obtenido por la prueba fue de 1 (superior al nivel de incertibumbre fijado para este experimento). 5.3 Prueba de una cola inferior El interés del investigador es probar que la media del ancho de grano es inferior a la actual. Prueba la hipótesis que la media de AG del tratamiento 3 es inferior a 9 mm. \\(H_0: \\mu \\ge 9~mm\\) \\(H_1: \\mu &lt; 9~mm\\) \\(\\alpha = 0.08\\) Utilice la prueba de t-student t.test(T3$AG, mu = 9, alternative = &quot;less&quot;) One Sample t-test data: T3$AG t = -8.2518, df = 79, p-value = 0.000000000001407 alternative hypothesis: true mean is less than 9 95 percent confidence interval: -Inf 8.505551 sample estimates: mean of x 8.380625 # Valor critico de la prueba qt(0.08,79) [1] -1.418424 Se observó que el valor crítico de la prueba fue de t = -1.418424. Si se logra obtener un valor de t calculado menor a el t crítico o tabular de la prueba, entonces se rechaza la hipótesis nula. El valor calculado de t fue de -88.189 (menor a -1.418424), obteniendo un p valor &lt; 0.001 (p &lt; 0.00000000000000022). Teniendo en cuenta que el nivel de alfa designado para la prueba fue de 0.08, entonces el t calculado está situado en la zona de rechazo de la hipótesis nula. La media calculada del ancho de grano en el tratamiento 3, fue de 8.38 mm. Conclusión se rechaza la hipótesis nula, con un nivel de significancia de 0.08, por lo tanto, hay suficiente evidencia estadística para afirmar que la media del AG en el tratamiento 3 es menor a 9 mm. Consideraciones Existen niveles de incertidumbre o niveles de significancia (\\(\\alpha\\)), que ayudan a saber cuanta probabilidad de tolerancia de cometer un error de tipo I, estamos dispuestos a aceptar. Existes cinco niveles de significancia ampliamente usados: No se rechaza la hipótesis nula cuando: - No significativo (n.s.): Cuando el p valor obtenido es mayor a 0.1. El criterio de rechazo de hipótesis nula, dependerá del investigador: - Marginal (m): Cuando el p valor obtenido es mayor a 0.05 y menor igual a 0.1. Se rechaza la hipótesis nula: - Significativo (): Cuando el p valor obtenido es menor igual a 0.05. - Altamente significativo (): Cuando el p valor obtenido es menor igual a 0.01. - Muy altamente significativo (): Cuando el p valor obtenido es menor igual a 0.001. En experimentos agrícolas, es común utilizar un p valor de 0.05, pero, según el nivel de confianza de las conclusiones que se desean tomar, se puede optar por otros valores de significancia. 5.4 Limites de confianza Es una estimación del parámetro por intervalo, es mejor que una estimación puntual. Halle los límites de confianza al 95 % del ancho de grano del tratamiento 1. Utilice t-student. with(T1, t.test(AG, conf.level = 0.95)) One Sample t-test data: AG t = 105.97, df = 79, p-value &lt; 0.00000000000000022 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: 9.063248 9.410252 sample estimates: mean of x 9.23675 El valor medio del ancho de grano en el tratamiento 1 fue de \\(9.23675 mm\\), su límite inferior fue de \\(9.063248\\) y su límite superior fue de \\(9.410252\\) al 95 % de confianza. with(T1, t.test(AG, conf.level = 0.95, alternative = &quot;less&quot;)) One Sample t-test data: AG t = 105.97, df = 79, p-value = 1 alternative hypothesis: true mean is less than 0 95 percent confidence interval: -Inf 9.381829 sample estimates: mean of x 9.23675 with(T1, t.test(AG, conf.level = 0.95, alternative = &quot;greater&quot;)) One Sample t-test data: AG t = 105.97, df = 79, p-value &lt; 0.00000000000000022 alternative hypothesis: true mean is greater than 0 95 percent confidence interval: 9.091671 Inf sample estimates: mean of x 9.23675 5.5 Prueba de dos colas Prueba la hipótesis que la media de la longitud de grano en el tratamiento 1 es diferente a la media de la longitud de grano en el tratamiento 3. \\(H_0: \\mu_{T1} = \\mu_{T3}\\) \\(H_1: \\mu_{T1} \\neq \\mu_{T3}\\) \\(H_0: \\mu_{T1} - \\mu_{T3} = 0\\) \\(H_1: \\mu_{T1} - \\mu_{T3} \\neq 0\\) \\(\\alpha = 0.03\\) Utilice la prueba de t-student Primero realice la prueba de homogeneidad de variancia \\(H_0: \\sigma_{T1} = \\sigma_{T3}\\) \\(H_1: \\sigma_{T1} \\neq \\sigma_{T3}\\) \\(H_0: \\frac{\\sigma_{T1}}{\\sigma_{T3}} = 1\\) \\(H_1: \\frac{\\sigma_{T1}}{\\sigma_{T3}} \\neq 1\\) \\(\\alpha = 0.1\\) Utilice la prueba de F var.test(T1$LG,T3$LG, conf.level = 0.90) F test to compare two variances data: T1$LG and T3$LG F = 0.62257, num df = 79, denom df = 79, p-value = 0.03664 alternative hypothesis: true ratio of variances is not equal to 1 90 percent confidence interval: 0.4290184 0.9034454 sample estimates: ratio of variances 0.6225711 Se rechaza la hipótesis nula, dado que el p.valor = 0.03664, es menor a 0.1, lo mínimo para no rechazar la hipótesis que concluye que las variancias son equivalentes. Conclusión A un nivel de significancia de 0.1, existe suficiente evidencia estadística para rechazar la hipótesis nula, por lo tanto, las variancias de longitud de grano de los tratamientos 1 y 3 no son equivalentes, entonces las variancias no son estadísticamente iguales. En la prueba de t-student debemos considerar estos resultados para realizar un ajuste de la prueba. t.test(T1$LG,T3$LG, conf.level = 0.97, alternative = &quot;two.sided&quot;, var = FALSE) Welch Two Sample t-test data: T1$LG and T3$LG t = 4.302, df = 149.89, p-value = 0.0000304 alternative hypothesis: true difference in means is not equal to 0 97 percent confidence interval: 0.3144217 0.9670783 sample estimates: mean of x mean of y 12.27925 11.63850 La media de la longitud de grano del tratamiento 1 fue de \\(12.27925\\) mm y en el tratamiento 3 fue de \\(11.63850\\) mm. La diferencia de las medias fue de \\(0.64075\\) mm, que tuvo un intervalo de confianza al \\(97\\%\\) con un valor superior de \\(0.9670783\\) mm y un valor inferior de \\(0.3144217\\) mm. El p valor fue de 0.0000304, menor al \\(\\alpha\\) de 0.03, por lo tanto se rechaza la hipótesis nula. Conclusión Con un nivel de significancia de 0.03, existe suficiente evidencia estadística para rechazar la hipótesis nula, por lo tanto, la diferencia de medias de la longitud de grano de los tratamientos 1 y 3 fue diferente estadísticamente de 0. Entonces, se puede concluir además, que el tratatamiento 1 posee una media estadísticamente diferente al tratamiento 3 con respecto a la longitud de grano. "],["pruebas-de-hipótesis-ii.html", "Chapter 6 Pruebas de hipótesis II 6.1 Prueba de hipótesis para k variancias 6.2 Prueba de k medias 6.3 Pruebas no paramétricas", " Chapter 6 Pruebas de hipótesis II 6.1 Prueba de hipótesis para k variancias Sirve para detectar si las variancias son constantes (homogéneas) o no constantes (heterogéneas) 6.1.1 Prueba de Barttlet Con DAP \\(H_0: \\sigma_{Aucatadijo} = \\sigma_{Bolaina} = \\sigma_{Shihuahuaco} = \\sigma_{Tornillo}\\) \\(H_1: \\text{Al menos un } \\sigma \\text{ es diferente a los demás}\\) \\(\\alpha = 0.01\\) data(&quot;bagua&quot;) dap &lt;- bagua %&gt;% select(dap,especie) %&gt;% filter(especie %in% c(&quot;Aucatadijo&quot;,&quot;Bolaina&quot;,&quot;Shihuahuaco&quot;,&quot;Tornillo&quot;)) dap$especie &lt;- dap$especie %&gt;% as.character %&gt;% as.factor # bartlett.test(especie$dap, especie$especie) bartlett.test(dap$dap~dap$especie) Bartlett test of homogeneity of variances data: dap$dap by dap$especie Bartlett&#39;s K-squared = 58.08, df = 3, p-value = 0.000000000001512 boxplot(dap$dap~dap$especie) Conclusión. A un nivel de significancia de 0.01, existe suficiente evidencia estadística para rechazar \\(H_0\\). Por lo tanto, se puede afirmar que la varianza del diámetro a la altura del pecho es diferente el al menos una de las especies. Con Altura \\(H_0: \\sigma_{Aucatadijo} = \\sigma_{Bolaina} = \\sigma_{Shihuahuaco} = \\sigma_{Tornillo}\\) \\(H_1: \\text{Al menos un } \\sigma \\text{ es diferente a los demás}\\) \\(\\alpha = 0.01\\) data(&quot;bagua&quot;) altura &lt;- bagua %&gt;% select(altura,especie) %&gt;% filter(especie %in% c(&quot;Aucatadijo&quot;,&quot;Bolaina&quot;,&quot;Shihuahuaco&quot;,&quot;Tornillo&quot;)) altura$especie &lt;- altura$especie %&gt;% as.character %&gt;% as.factor bartlett.test(altura$altura~altura$especie) Bartlett test of homogeneity of variances data: altura$altura by altura$especie Bartlett&#39;s K-squared = 0.22799, df = 3, p-value = 0.9729 boxplot(altura$altura~altura$especie) Conclusión. A un nivel de significancia de 0.01, existe suficiente evidencia estadística para no rechazar \\(H_0\\). Por lo tanto, se puede afirmar que la varianza de la altura del árbol no es diferente entre las especies. 6.2 Prueba de k medias \\(H_0: \\mu_{Aucatadijo} = \\mu_{Bolaina} = \\mu_{Shihuahuaco} = \\mu_{Tornillo}\\) \\(H_1: \\text{Al menos un } \\mu \\text{ es diferente a los demás}\\) \\(\\alpha = 0.07\\) Esta prueba tiene como supuesto que la dispersión o varianza de los niveles del factor evaluado es estadísticamente similar entre los niveles. data(&quot;bagua&quot;) summary(aov(lm(altura~especie, altura))) Df Sum Sq Mean Sq F value Pr(&gt;F) especie 3 1.43 0.4753 1.366 0.253 Residuals 267 92.89 0.3479 cat(&quot;F tabular al 0.07 de alfa:&quot;,qf(0.07,3,267, lower.tail = F),&quot;.\\n&quot;) F tabular al 0.07 de alfa: 2.380331 . Conclusión. A un nivel de significancia de 0.07, existe suficiente evidencia estadística para no rechazar \\(H_0\\). Por lo tanto puede afirmar que la altura de planta es estadísticamente similar entre las especies Aucatadijo, Bolaina, Shihuahuaco y Tornillo. 6.3 Pruebas no paramétricas 6.3.1 Prueba U de Mann-Whitney \\(H_0: Mediana_{Aucatadijo} = Mediana_{Shihuahuaco}\\) \\(H_1: Mediana_{Aucatadijo} \\neq Mediana_{Shihuahuaco}\\) \\(\\alpha = 0.05\\) dap2 &lt;- bagua %&gt;% select(dap,especie) %&gt;% filter(especie %in% c(&quot;Aucatadijo&quot;,&quot;Shihuahuaco&quot;)) Aucatadijo &lt;- dap2%&gt;% filter(especie %in% c(&quot;Aucatadijo&quot;)) Shihuahuaco &lt;- dap2%&gt;% filter(especie %in% c(&quot;Shihuahuaco&quot;)) wilcox.exact(Aucatadijo$dap,Shihuahuaco$dap, mu = 0, paired = F, alternative = &quot;t&quot;) Asymptotic Wilcoxon rank sum test data: Aucatadijo$dap and Shihuahuaco$dap W = 0, p-value &lt; 0.00000000000000022 alternative hypothesis: true mu is not equal to 0 Conclusión. A un nivel de significancia de 0.05, existe suficiente evidencia estadística para rechazar la \\(H_0\\). Por lo tanto, podemos afirmar que el dap mediano de la especie Aucatadijo es diferente al de la especie Shihuahuaco. 6.3.2 Prueba Mood \\(H_0: \\theta_{Aucatadijo} = \\theta_{Shihuahuaco}\\) \\(H_1: \\theta_{Aucatadijo} \\neq \\theta_{Shihuahuaco}\\) \\(\\alpha = 0.05\\) mood.test(Aucatadijo$dap,Shihuahuaco$dap, alternative = &quot;t&quot;) Mood two-sample test of scale data: Aucatadijo$dap and Shihuahuaco$dap Z = 1.6134, p-value = 0.1067 alternative hypothesis: two.sided Conclusión. A un nivel de significancia de 0.05, existe suficiente evidencia estadística para no rechazar la \\(H_0\\). Por lo tanto, podemos afirmar que la diferencia en la dispersión del diámetro a la altura del pecho de la especie Aucatadijo es igual al de la especie Shihuahuaco. 6.3.3 Prueba Kruskal Wallis \\(H_0: \\text{El dap de las especies provienen de la misma distribución}\\) \\(H_1: \\text{El dap de las especies no provienen de la misma distribución}\\) kSamples::ad.test(dap$dap~dap$especie) Anderson-Darling k-sample test. Number of samples: 4 Sample sizes: 53, 89, 69, 60 Number of ties: 220 Mean of Anderson-Darling Criterion: 3 Standard deviation of Anderson-Darling Criterion: 1.30473 T.AD = ( Anderson-Darling Criterion - mean)/sigma Null Hypothesis: All samples come from a common population. AD T.AD asympt. P-value version 1: 121 90.46 0.0000000000000000000000000000000000000000000000000000000001908000 version 2: 126 94.39 0.0000000000000000000000000000000000000000000000000000000000002719 \\(H_0: Mediana_{Aucatadijo} = Mediana_{Bolaina} = Mediana_{Shihuahuaco} = Mediana_{Tornillo}\\) \\(H_1: \\text{Al menos una Mediana es diferente a las demás}\\) with(dap,kruskal(y = dap,trt = especie,alpha = 0.05,group = T,console = T)) Study: dap ~ especie Kruskal-Wallis test&#39;s Ties or no Ties Critical Value: 218.2316 Degrees of freedom: 3 Pvalue Chisq : 0 especie, means of the ranks dap r Aucatadijo 105.54717 53 Bolaina 51.22472 89 Shihuahuaco 206.34783 69 Tornillo 207.75000 60 Post Hoc Analysis t-Student: 1.968889 Alpha : 0.05 Groups according to probability of treatment differences and alpha level. Treatments with the same letter are not significantly different. dap groups Tornillo 207.75000 a Shihuahuaco 206.34783 a Aucatadijo 105.54717 b Bolaina 51.22472 c 6.3.4 Prueba de la Mediana \\(H_0: Mediana_{Aucatadijo} = Mediana_{Bolaina} = Mediana_{Shihuahuaco} = Mediana_{Tornillo}\\) \\(H_1: \\text{Al menos una Mediana es diferente a las demás}\\) with(dap,Median.test(y = dap,trt = especie,alpha = 0.05,group = T,console = T)) The Median Test for dap ~ especie Chi Square = 249.7167 DF = 3 P.Value 0.000000000000000000000000000000000000000000000000000007535327 Median = 0.65 Median r Min Max Q25 Q75 Aucatadijo 0.58 53 0.46 0.68 0.54 0.62 Bolaina 0.49 89 0.41 0.55 0.45 0.52 Shihuahuaco 1.15 69 0.98 1.32 1.07 1.20 Tornillo 1.15 60 0.78 1.32 1.10 1.22 Post Hoc Analysis Groups according to probability of treatment differences and alpha level. Treatments with the same letter are not significantly different. dap groups Shihuahuaco 1.15 a Tornillo 1.15 a Aucatadijo 0.58 b Bolaina 0.49 c "],["muestreo-aplicado.html", "Chapter 7 Muestreo aplicado 7.1 Estimar una respuesta cuantitativa 7.2 Estimar una respuesta cualitativa", " Chapter 7 Muestreo aplicado El muestreo es una técnica estadística que permite extraer individuos de una población con la condición de representar en pequeño la ocurrencia en la población, desde parámetros hasta características particulares de interés. Hay dos tipos de muestreo: Probabilístico. No Probabilístico. El primero requiere un ingrediente aleatorio y el no probabilístico es completamente dirigido, realizado en forma personalizada por el observador. 7.1 Estimar una respuesta cuantitativa En el caso de de muestreo probabilístico, en un muestreo aleatorio, el tamaño de la muestra si es obtenida bajo los criterios de confianza, tolerancia y variabilidad, esta será considerada como una muestra con tamaño óptimo. \\[n_0 = \\frac{t_{0.05}^2*S^2}{\\text{tol}^2}\\] \\(n_0\\): tamaño de muestre preliminar. \\(t_{0.05}\\): es el valor del cuantil de t al 95 % de confianza, en la práctica es 1.96. El valor de puede cambiar a gusto o necesidad del investigador. \\(S^2\\): Variancia estimada de la población o rando al cuadrado para un número pequeño (muestra preliminar) para la estiamción correspondiente. tol: Tolerancia, expresado en diferencia a considerar entre el valor real o verdadero y el posible valor determinado. \\[n_1 = \\frac{n_0}{1+\\frac{n_0}{N}}\\] Aplicar en el inventario de Isabelita, estimar el diámetro (DAP) de la especie SHIHUAHUACO. data(&quot;Isabelita&quot;) SHI &lt;- subset(Isabelita, especie == &quot;SHIHUAHUACO&quot;) head(SHI[,1:10]) este norte N bloque faja estrada codigo especie dap altura 7 402324 8764725 7 I 1 66 2 SHIHUAHUACO 1.7 15 15 402301 8764615 15 I 1 64 5 SHIHUAHUACO 1.0 16 22 402291 8764270 22 I 1 59 74 SHIHUAHUACO 0.6 12 39 402291 8764362 39 I 1 50 16 SHIHUAHUACO 1.4 14 40 402291 8764270 40 I 1 49 77 SHIHUAHUACO 0.9 13 42 402291 8763675 42 I 1 45 79 SHIHUAHUACO 1.2 14 7.1.1 Muestreo piloto para tener una idea de la variación set.seed(123) n0 &lt;- sample(1:949,6) n1 &lt;- SHI[n0,] r &lt;- max(n1$dap)-min(n1$dap) r [1] 0.7 Es un estimado de la desviación de los datos (rango), al cuadrado será un estimado de la variancia. El rango se debe utilizar cuando se tiene como máximo 10 observaciones en la muestra preliminar. set.seed(123) n0 &lt;- sample(1:nrow(SHI),50) n1 &lt;- SHI[n0,] sd &lt;- sd(n1$dap) sd [1] 0.2842822 Se elige a la desviación estándar (\\(s\\)), como un estimador de la desviación de los datos cuando se tiene más de 10 observaciones en la muestra preliminar. La desviación estándar al cuadrado de la muestra preliminar nos dará una proyección de la variancia de la población. Se fija un \\(95\\%\\) de confianza (1.96) y una tolerancia, por ejemplo, de \\(1.2*0.1=0.12\\) y la variancia es \\(s^2\\). xhat &lt;- mean(n1$dap) # xhat tol &lt;- xhat*0.1 # tol N &lt;- nrow(SHI) n &lt;- qnorm(0.975)^2*sd^2/tol^2 n &lt;- round(n+0.5,0) n &lt;- n/(1+n/N) n &lt;- round(n+0.5,0) cat(&quot;Tamaño de muestra ótpimo para DAP:&quot;, n, &quot;\\n&quot;) Tamaño de muestra ótpimo para DAP: 27 Estimar DAP n0 &lt;- sample(1:nrow(SHI),n) muestra &lt;- SHI[n0,] summary(muestra$dap) Min. 1st Qu. Median Mean 3rd Qu. Max. 0.600 0.900 1.000 1.069 1.200 1.700 7.2 Estimar una respuesta cualitativa El interés pueder ser, conocer el número y las especies que hay en la localidad en base a una muestra. Utilizando la misma fórmula de tamaño de muestra, se realiza las siguientes aproximaciones: \\(S^2\\) aproximado de la variancia poblacional de una proporción entre dos alternativas y la máxima variancia es 0.5*0.5 = 0.25 = p(1-p). Tol es reemplazada por el margen de error a cometer en la estimación. Si es \\(10\\%\\) significa que la tolerancia es \\(0.1\\) \\[n = \\frac{t_{0.05}^2*S^2}{tol^2}\\] En el caso de población finita (N), se realiza una corrección: \\[n = \\frac{n_0}{1+\\frac{n_0}{N}}\\] Aplicación en el inventario Isabelita, estimar el número y las especies que existen utilizando una muestra óptima. n &lt;- qnorm(0.975)^2*0.5^2/0.05^2 N &lt;- nrow(Isabelita) n &lt;- n/(1+n/N) n &lt;- round(n+0.5,0) cat(&quot;Tamaño de muestra óptimo para estimar el número de especies:&quot;, n, &quot;\\n&quot;) Tamaño de muestra óptimo para estimar el número de especies: 359 n0 &lt;- sample(1:N,n) muestra &lt;- Isabelita[n0,] table(muestra$especie) -&gt; tabla cat(&quot;Total de especies en la muestra:&quot;, length(tabla), &quot;\\n&quot;) Total de especies en la muestra: 20 tabla ANACASPI AZUCAR HUAYO CACHIMBO CAPIRONA CATAHUA CATUABA CEDRO COPAIBA ESTORAQUE 19 13 5 2 14 8 1 6 26 ISHPINGO ITAUBA LUPUNA PALO BASTON PONA PUMAQUIRO QUILLOBORDON QUINILLA SHIHUAHUACO 19 9 1 15 128 2 4 18 59 TAHUARI YACUSHAPANA 5 5 "],["medidas-de-asociación-y-regresión.html", "Chapter 8 Medidas de asociación y regresión 8.1 Correlación 8.2 Otros métodos 8.3 Regresión", " Chapter 8 Medidas de asociación y regresión 8.1 Correlación Creador de la medida fue Pearson. La idea es mostrar una relación conjunta de dos o más variables aleatorias en un indicador que varia entre -1 y 1, de tal manera que se pueda interpretar la realción real de las medidas. 8.1.1 Valor de la correlación Negativo: relación inversa. A medida que una variable aumenta su media, la otra disminuye. Positivo: relación directa. A medida que una variable aumenta su media, la otra también aumenta. 0: neutro, no hay relación. Interpretación: Se basa en la magnitud y en signo. Si el valor está cercano a 1 o -1 es una correlación alta. 8.1.2 Prueba estadística La hipótesis es que no existe correlación. Entonces la prueba estadística tiene que mostrar rechazando esta hipótesis y así concluir que la correlación existe. \\(H_0: \\rho = 0~\\text{(no existe relación)}\\) \\(H_1: \\rho \\neq 0~\\text{(existe relación)}\\) Para fundamentar la respuesta, requiere un número aceptable de pares de datos de la distribución normal bivariada para realizar la prueba que debe ser cercana a 30 observaciones. Si se tiene muchos datos, lo conveniente es extraer al azar un número aproximado a 30. 8.1.3 Gráfico de la dispersión Permite visualizar la relación existente. Totalmente disperso, no hay relación. La variancia entre las variables es aleatoria. Muestra tendencia (+) o (-) indica que hay relación, se traduce como asociación y en estadística se describe como correlación. Procedimientos: plot(), pairs() 8.1.4 Tipo de variable El tipo de variable nos indica que procedimiento se debe aplicar para medir la asociación. Pearson: Variables cuantitativas, observadas de instrumentos de medición. Necesita de cumplimiento del supuesto de normalidad bivariada. Spearman: Variables cuantitativas ordinales (escala jerárquica) cuanto menos (se puede utilizar en variables cuantitativas discretas y continuas). No necesita de cumplimiento del supuesto de normalidad bivariada. Kendall: Variables cuantitatitas ordinales (escala jerárquica) cuyo objetivo es establecer concordancia en las medidas. Cramer: Variables cualitativas nominales u, elaborado ordinal. Requiere una tabla de contingencia obtenida de una encuesta. 8.1.5 Aplicación Para crear un modelo de regresión lineal simple se tomó como variable dependiente al Recuento de escarabajos en un área. Las posibles variables predictoras fueron: Temperatura: Temperatura (°C) ambiental. Altura: Altura (m.s.n.m.) de la observación. Humedad: Humedad relativa (%) ambiental. Machos: Género predominante en el área (0 si predominan hembras, 1 si predominan machos). Urbano: 0 (No) si el conteo se hizo en un área no urbana, 1 (Sí) si el conteo se hizo en un área urbana. 8.1.5.1 Dispersión y valor de la correlación Dispersión entre la temperatura y el recuento op &lt;- par(mar = c(4,4,2,2), cex = 0.8) with(datos,plot(Temperatura,Recuento,pch=19,bty=&quot;l&quot;)) with(datos,cor(Temperatura,Recuento)) -&gt; r r &lt;- round(r,3) v &lt;- paste(&quot;r=&quot;,r,sep=&quot;&quot;) text(28,300,v,cex=2) par(op) Dispersión entre la altura y el recuento op &lt;- par(mar = c(4,4,2,2), cex = 0.8) with(datos,plot(Altura,Recuento,pch=19,bty=&quot;l&quot;)) with(datos,cor(Altura,Recuento)) -&gt; r r &lt;- round(r,3) v &lt;- paste(&quot;r=&quot;,r,sep=&quot;&quot;) text(100,300,v,cex=2) par(op) Nota: La correlación se expresa en valores entre -1 y 1. No utilizar porcentaje. 8.1.5.2 Prueba estadística Prueba de hipótesis entre la temperatura y el recuento En primer lugar se comprueba que exista normalidad bivariada entre la Temperatura y el Recuento. Se genera la hipótesis estadística de la prueba de normalidad bivariada (supuesto de la prueba de hipótesis de correlación de pearson). \\(H_0: \\text{Existe distribución normal bivariada entre la temperatura y el recuento}\\) \\(H_1: \\text{No existe distribución normal bivariada entre la temperatura y el recuento}\\) Se debe confirmar la existencia de distribución normal bivariada entre la temperatura y el recuento, por ello, es obligatorio no rechazar la hipótesis nula para continuar con la prueba. mvnormtest::mshapiro.test(t(datos[,c(1,6)])) Shapiro-Wilk normality test data: Z W = 0.98964, p-value = 0.1583 Conclusión. Con una significancia de 0.1, existe suficiente evidencia estadística para concluir que hay normalidad bivariada en la distribución entre la temperatura y el recuento. Se puede continuar con la prueba de hipótesis de la correlación. Antes de realizar la prueba de hipótesis de la correlación de Pearson, se contruyó la siguiente hipótesis \\(H_0: \\rho = 0~\\text{(no existe relación entre la temperatura y el recuento)}\\) \\(H_1: \\rho \\neq 0~\\text{(existe relación entre la temperatura y el recuento)}\\) cor &lt;- with(datos,cor.test(Temperatura,Recuento,method=&quot;pearson&quot;, conf.level = 0.97)) with(datos,cor.test(Temperatura,Recuento,method=&quot;pearson&quot;, conf.level = 0.97)) Pearson&#39;s product-moment correlation data: Temperatura and Recuento t = 1.0103, df = 198, p-value = 0.3136 alternative hypothesis: true correlation is not equal to 0 97 percent confidence interval: -0.08268398 0.22256378 sample estimates: cor 0.07161654 Conclusión. A un nivel de \\(\\alpha\\) de 0.03, se evidencia que el valor de \\(\\rho\\) es estadísticamente similar a 0, por lo tanto, se concluye que no existe relación entre la temperatura y el recuento. En el análisis se tiene: valor de t: Estadístico de la prueba. p-value: En términos de riesgo, indica la probabilidad de rechazar la hipótesis nula siendo esta verdadera. En nuestro caso la probabilidad fue de 0.3135711 nos indica que existe una probabilidad de error de equivocarnos de 31.4%. En teoría el p-value es la probabilidad de rechazar la \\(H_0\\) siendo esta verdadera. En correlación la \\(H_0\\) es planteada como la no existencia de correlación, es decir = 0. Alternativamente se tiene los límites de confianza. Para no rechazar la \\(H_0\\) mediante los límites de confianza, estos deben encerrar al valor de 0 (cero incluido en el intervalo). Alternativa de la hipótesis: 1: hipótesis de un solo lado, solo menor o mayor. Si el interés es probar que la correlación sea buena y mayor de 0.6, entonces la hipótesis nula será: \\(H_0: \\rho \\le 0.6\\) cuya alternante será \\(H_1: \\rho &gt; 0.6\\) 2 colas: hipótesis de ambos lados (diferencia de cero). \\(H_0: \\rho = 0.6\\) cuya alternante será \\(H_1: \\rho \\neq 0.6\\) Prueba de hipótesis entre la altura y el recuento En primer lugar se comprueba que exista normalidad bivariada entre la altura y el Recuento. Se genera la hipótesis estadística de la prueba de normalidad bivariada (supuesto de la prueba de hipótesis de correlación de pearson). \\(H_0: \\text{Existe distribución normal bivariada entre la altura y el recuento}\\) \\(H_1: \\text{No existe distribución normal bivariada entre la altura y el recuento}\\) Se debe confirmar la existencia de distribución normal bivariada entre la altura y el recuento, por ello, es obligatorio no rechazar la hipótesis nula para continuar con la prueba. mvnormtest::mshapiro.test(t(datos[,c(2,6)])) Shapiro-Wilk normality test data: Z W = 0.99128, p-value = 0.2729 Conclusión. Con una significancia de 0.1, existe suficiente evidencia estadística para concluir que hay normalidad bivariada en la distribución entre la altura y el recuento. Se puede continuar con la prueba de hipótesis de la correlación. Antes de realizar la prueba de hipótesis de la correlación de Pearson, se contruyó la siguiente hipótesis: \\(H_0: \\rho = 0~\\text{(no existe relación entre la altura y el recuento)}\\) \\(H_1: \\rho \\neq 0~\\text{(existe relación entre la altura y el recuento)}\\) with(datos,cor.test(Altura,Recuento,method=&quot;pearson&quot;, conf.level = 0.99)) Pearson&#39;s product-moment correlation data: Altura and Recuento t = 107.04, df = 198, p-value &lt; 0.00000000000000022 alternative hypothesis: true correlation is not equal to 0 99 percent confidence interval: 0.9877111 0.9940831 sample estimates: cor 0.9914704 Conclusión. A un nivel de de 0.01, se evidencia que el valor de no es estadísticamente similar a 0, por lo tanto, se concluye que existe relación entre la altura y el recuento. 8.2 Otros métodos 8.2.1 Método de Spearman Pearson utiliza los medidos y Spearman con datos en escala de orden (como mínimo). Para una mejor observarción del comportamiento de la correlación, se utilizara datos de suelo. op &lt;- par(mar=c(4,4,2,2),cex = 0.8) data(soil) panel.cor &lt;- function(x,y,digits = 3, prefix = &quot;&quot;, cex.cor, ...) { usr &lt;- par(&quot;usr&quot;); on.exit(par(usr)) par(usr = c(0,1,0,1)) r &lt;- abs(cor(x,y)) txt &lt;- format(c(r, 0.123456789), digits = digits)[1] txt &lt;- paste0(prefix,txt) if(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt) text(0.5,0.5,txt,cex=cex.cor*r) } pairs(soil[6:10], upper.panel = panel.cor, lower.panel = panel.smooth) Matriz de correlación r &lt;- correlation(soil[,6:10],method = &quot;spearman&quot;) r$correlation CIC P K sand slime CIC 1.00 0.67 0.62 -0.54 0.52 P 0.67 1.00 0.69 -0.20 0.34 K 0.62 0.69 1.00 -0.41 0.39 sand -0.54 -0.20 -0.41 1.00 -0.80 slime 0.52 0.34 0.39 -0.80 1.00 round(r$pvalue,4) CIC P K sand slime CIC 1.0000 0.0122 0.0252 0.0588 0.0668 P 0.0122 1.0000 0.0095 0.5047 0.2500 K 0.0252 0.0095 1.0000 0.1611 0.1869 sand 0.0588 0.5047 0.1611 1.0000 0.0011 slime 0.0668 0.2500 0.1869 0.0011 1.0000 Se observa que la correlación arena vs limo es alta (r = -0.8) negativamente significativa que hay una relación inversa entre ambos. op &lt;- par(mar = c(4,4,2,2),cex = 0.8) with(soil,plot(sand, slime, pch = 19, col=&quot;blue&quot;, bty =&quot;l&quot;)) par(op) 8.2.2 Gráfico exploratorio datos %&gt;% select_if(is.numeric)%&gt;% pairs datos %&gt;% select_if(is.numeric)%&gt;% pairs.panels(stars = T,smooth = F, lm = T) datos%&gt;% ggpairs + theme_bw() datos%&gt;% ggpairs(upper = list(continuous = &quot;density&quot;, combo = &quot;box_no_facet&quot;), lower = list(continuous = &quot;points&quot;, combo = &quot;dot_no_facet&quot;)) + theme_test() 8.3 Regresión Se busca construir un modelo lineal simple, que permita predecir la respuesta mediante un modelo lineal de primer grado. Se entiende que la variable respuesta (dependiente) expuesta a ser predicha, debe ser aleatoria y la variable explicativa (independiente) debe ser fija no sujeta a error. Para estimar un mejor modelo de regresión, se debe utilizar observaciones lo más diferentes para contemplar el dominio de la respuesta. \\[Y_i=\\beta_0 + \\beta_1 X_i + \\epsilon_i\\] \\(X_i\\): Variable independiente (en este ejercicio es la altura). \\(Y_i\\): Variable respuesta, dependiente de \\(X_i\\) (en este ejercicio es el recuento). \\(\\beta_0\\): parámetro intercepto. Tiene unidades de la variable respuesta. Es el valor (media condicional) que tomará el recuento cuando la altura sea cero. \\(\\beta_1\\): parámetro pendiente, tasa de cambio de \\(Y\\) al aumentar una unidad en \\(X\\), las unidades de este parámetro es la razón entre \\(Y\\) y \\(X\\). \\(\\epsilon_i\\): Error aleatorio del modelo. Es un vector de errores o residuos que se calcula con la diferencia entre el valor real y observado de la variable respuesta con el valor ajustado o predicho de esta variable. \\[\\epsilon_i = Y_i - \\hat{Y}_i\\] donde: \\(\\hat{Y}_i\\) es el valor ajustado o predicho de la variable respuesta, se obtiene de la siguiente manera: \\[\\hat{Y}_i = \\beta_0 + \\beta_1 X_i\\] 8.3.1 Aplicación Usar las variables Altura (indendiente) y Recuento (Dependiente). A continuación presentamos el modelo de regresión lineal. \\[Recuento_i = \\beta_0+\\beta_1*Altura_i+\\epsilon_i\\] Teniendo en cuenta los valores repetidos es apropiado promediar, para tener valores únicos y que sean lo más distinto posible. Este procedimiento no es obligatorio. op &lt;- par(mar = c(4,4,2,2),cex = 0.8) recmean &lt;- with(datos,tapply.stat(Altura,Recuento,mean)) with(datos,plot(Altura, Recuento, pch = 19, bty = &quot;l&quot;, main = &quot;Recuento sin promediar según la altura&quot;)) with(recmean,plot(Altura, Recuento, pch = 19, bty = &quot;l&quot;, main = &quot;Recuento promediado según la altura&quot;)) par(op) 8.3.1.1 Construcción del modelo modelo &lt;- lm(Recuento ~ Altura, data = recmean) summary(modelo) Call: lm(formula = Recuento ~ Altura, data = recmean) Residuals: Min 1Q Median 3Q Max -18.9829 -5.7816 -0.5109 6.3318 25.2946 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 59.501813 1.505497 39.52 &lt;0.0000000000000002 *** Altura 0.537036 0.005229 102.70 &lt;0.0000000000000002 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 8.698 on 144 degrees of freedom Multiple R-squared: 0.9865, Adjusted R-squared: 0.9864 F-statistic: 1.055e+04 on 1 and 144 DF, p-value: &lt; 0.00000000000000022 Hipótesis generadas: Para el \\(\\beta_0\\) (intercepto). \\(H_0: \\beta_0 = 0\\) \\(H_1: \\beta_0 \\neq 0\\) Para el \\(\\beta_1\\) (pendiente). \\(H_0: \\beta_1 = 0\\) \\(H_1: \\beta_1 \\neq 0\\) En el resumen se tiene la descripción del modelo. La estimación de los parámetros con su significación estadística. Las estadísticas de los errores. Error estándar del modelo = raíz cuadrada del cuadrado medio del error. \\(R^2\\) mide el grado de determinación del modelo (importancia o explicación de la variancia de la varible independiente sobre la dependiente) solo para modelo de regresión lineal simple. \\(R^2\\) ajustado, mide el grado de determinación del modelo lineal de muchas variables. Es una medida penalizada por el tamaño de muestra. Prueba del modelo mediante la prueba de F para la acaptación del modelo. De acuerdo a nuestro análisis \\(\\hat \\beta_0 = -105.89891\\) \\(\\hat \\beta_1 = 1.83699\\) El intercepto no es interpretable, porque el dominio de la variable recuento no considera valores menores a 0. Ambos coeficientes son significativos según el pvalue. \\(R^2=0.9865\\) que equivale a decir que la altura explica el \\(98.65\\%\\) de la variancia del recuento. el p-value fue de &lt; 0.00000000000000022, es cero, se concluye que el modelo es aceptable o tiene buenas variables regresoras. 8.3.1.2 Análisis de variancia Prueba de hipótesis del ANOVA para una regresión: \\(H_0: \\text{La variable regresora tiene una influencia no significativa sobre la variable predicha}\\) \\(H_1: \\text{La variable regresora tiene una influencia significativa sobre la variable predicha}\\) anova(modelo) Analysis of Variance Table Response: Recuento Df Sum Sq Mean Sq F value Pr(&gt;F) Altura 1 798016 798016 10548 &lt; 0.00000000000000022 *** Residuals 144 10894 76 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 cat(&quot;F tabular al 0.05 de alfa:&quot;,qf(0.05,1,144,lower.tail = F),&quot;.\\n&quot;) F tabular al 0.05 de alfa: 3.906849 . cat(&quot;F tabular al 0.01 de alfa:&quot;,qf(0.01,1,144,lower.tail = F),&quot;.\\n&quot;) F tabular al 0.01 de alfa: 6.814199 . cat(&quot;F tabular al 0.005 de alfa:&quot;,qf(0.005,1,144,lower.tail = F),&quot;.\\n&quot;) F tabular al 0.005 de alfa: 8.127817 . cat(&quot;F tabular al 0.001 de alfa:&quot;,qf(0.001,1,144,lower.tail = F),&quot;.\\n&quot;) F tabular al 0.001 de alfa: 11.28538 . 8.3.1.3 Gráfico del modelo: op &lt;- par(mar=c(4,4,2,2), cex = 0.8) with(recmean,plot(Altura, Recuento, pch = 19, bty = &quot;l&quot;)) abline(modelo, col = &quot;blue&quot;) par(op) 8.3.1.4 Gráfico de los supuestos del modelo: op &lt;- par(mfrow=c(2,2), cex = 0.8) plot(modelo) par(op) 1. Falta de ajuste Se analiza, si falta ajustar mejor el modelo, la línea roja es la que nos permite entender si se debe agregar algunos términos más en el modelo. En este caso hay posibilidad de hacer un ajuste en el modelo. 2. La normalidad Los puntos deben estar sobre la línea (perfecta normalidad en los errores). Se puede hacer un gráfico de normalidad y una prueba de hipótesis. 3. La magnitud del error Es un gráfico estándar para detectar errores muy grandes. Es tolerable valores menores a 1.5. Para este ejercicio, existen tres posibles valores con errores críticos. 4. Valores extremos En el gráfico se puede detectar los outliers, que son posibles valores influyentes en el comportamiento del modelo. No hay valores extremos en el ejemplo. 8.3.1.5 Ajuste del modelo modelo1 &lt;- lm(Recuento ~ Altura + I(Altura^2), data = recmean) summary(modelo1) Call: lm(formula = Recuento ~ Altura + I(Altura^2), data = recmean) Residuals: Min 1Q Median 3Q Max -19.7192 -5.8774 -0.4817 6.0545 25.3046 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 57.2889837 2.7238017 21.033 &lt;0.0000000000000002 *** Altura 0.5598169 0.0239453 23.379 &lt;0.0000000000000002 *** I(Altura^2) -0.0000428 0.0000439 -0.975 0.331 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 8.7 on 143 degrees of freedom Multiple R-squared: 0.9866, Adjusted R-squared: 0.9864 F-statistic: 5273 on 2 and 143 DF, p-value: &lt; 0.00000000000000022 El termino polinomial cuadrático de la Altura de planta, no posee una explicación de la variancia o no aporta en la linealidad del modelo. 8.3.1.6 La normalidad de los errores. op &lt;- par(mar = c(4,4,2,2), cex=0.8) error &lt;- residuals(modelo) plot(density(error), main = &quot;Distribución del error&quot;) shapiro.test(error) Shapiro-Wilk normality test data: error W = 0.98802, p-value = 0.2423 par(op) Prueba de hipótesis de la normalidad: \\(H_0: \\text{La distribución de los errores se distribuye de forma similar a la función normal o gaussiana}\\) \\(H_1: \\text{La distribución de los errores no se distribuye de forma similar a la función normal o gaussiana}\\) Conclusión. A un nivel de significancia de 0.1, se concluye que no existe suficiente evidencia estadística para rechazar la hipótesis nula, por lo tanto, la distribución de los errores es similar a la función normal. 8.3.1.7 Predecir el recuento de escarabajos en una altura propuesta. Cálculo de los valores predichos del modelo con los datos observados pred &lt;- predict(modelo) recmean$prediccion &lt;- pred head(recmean) Recuento Altura prediccion 1 67 42 82.05732 2 68 39 80.44621 3 69 39 80.44621 4 72 25 72.92771 5 83 67 95.48321 6 84 30 75.61289 ggplot(recmean, aes(x = `Recuento`, y = `prediccion`)) + geom_point() + labs(y = &quot;Recuento predicho&quot;, x = &quot;Recuento real&quot;) + geom_abline(intercept = 0, col = &quot;red&quot;) Cálculo de una predicción en un valor estacionario Predecir el recuento de escarabajos en altura de 100, 500, y 4000 m.s.n.m. altnuevo &lt;- c(100,500,4000) recnuevo &lt;- predict(modelo, newdata = data.frame(Altura = altnuevo)) cbind(altnuevo, recnuevo) altnuevo recnuevo 1 100 113.2054 2 500 328.0197 3 4000 2207.6450 "],["análisis-de-componentes-principales.html", "Chapter 9 Análisis de componentes principales 9.1 Introducción 9.2 ¿Que es un componente? 9.3 ¿Cómo se seleccionan los componentes principales? 9.4 Aplicación: Caso Maíz", " Chapter 9 Análisis de componentes principales 9.1 Introducción El Análisis de Componentes Principales (Principal Component Analysis), es una técnica multivariada que tiene como objetivo reducir la dimensionalidad, es decir, explicar con el menor número de variables posibles, la mayor cantidad de variancia del experimento. Para ello, se crea un nuevo conjunto de variables a la cual llamaremos componentes. El PCA tiene un uso exploratorio y descriptivo. Se emplea para variables cuantitativas. Es la puerta de entrada para la creación de modelos inferenciales y predictivos. 9.2 ¿Que es un componente? Es una variable creada por la relación lineal entre distintas variables originales. Los componentes son variables ortogonales, es decir, su correlación entre ellas es nula. 9.3 ¿Cómo se seleccionan los componentes principales? Se seleccionan a través de tres criterios: Criterio práctico: Seleccionar a los dos primeros componentes. Criterio de la media aritmétrica. Seleccionar a todos aquellos componentes que expliquen la variancia de más de una varible original. Es se observa en el autovalor (). Si es mayor a 1, se elige este componente como principal. Criterio del gráfico de sedimentación. Es muy similar al criterio de la media aritmétrica. En ese criterio se usa un gráfico en forma de media montaña, donde se observa que a medida que aumenta el número de componentes, se va disminuyendo la explicación de la variancia del componente creado. 9.4 Aplicación: Caso Maíz Tratamiento &lt;- factor(maiz$Tratamiento) data.PCA &lt;- maiz%&gt;% select(HPP, GPM, LG, AG, PM) 9.4.1 Correlación de variables cor &lt;- cor(data.PCA) corrplot(cor) p.mat &lt;- cor_pmat(data.PCA) ggcorrplot(cor, hc.order = F, type = &quot;lower&quot;, p.mat = p.mat) ggcorrplot(cor, hc.order = F, type = &quot;lower&quot;, p.mat = p.mat, insig = &quot;blank&quot;) 9.4.2 Análisis de componentes principales Forma 1 acp &lt;- FactoMineR::PCA(data.PCA, scale.unit = T, ncp = 5, graph = F) summary(acp) Call: FactoMineR::PCA(X = data.PCA, scale.unit = T, ncp = 5, graph = F) Eigenvalues Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 Variance 1.719 1.536 1.035 0.442 0.268 % of var. 34.386 30.713 20.699 8.846 5.356 Cumulative % of var. 34.386 65.099 85.798 94.644 100.000 Individuals (the 10 first) Dist Dim.1 ctr cos2 Dim.2 ctr cos2 Dim.3 ctr cos2 1 | 2.320 | 2.101 0.401 0.820 | -0.078 0.001 0.001 | -0.978 0.144 0.178 | 2 | 2.013 | 0.611 0.034 0.092 | 0.101 0.001 0.003 | -1.801 0.490 0.800 | 3 | 1.650 | 1.381 0.173 0.701 | 0.290 0.009 0.031 | -0.780 0.092 0.223 | 4 | 2.680 | -0.571 0.030 0.045 | -0.778 0.062 0.084 | -2.479 0.927 0.855 | 5 | 0.935 | 0.793 0.057 0.719 | -0.144 0.002 0.024 | -0.408 0.025 0.190 | 6 | 1.477 | 0.477 0.021 0.104 | -0.547 0.030 0.137 | -1.163 0.204 0.620 | 7 | 1.788 | 0.337 0.010 0.036 | -0.602 0.037 0.113 | -1.613 0.393 0.814 | 8 | 1.330 | 0.608 0.034 0.209 | 0.381 0.015 0.082 | -1.059 0.169 0.634 | 9 | 2.209 | 2.057 0.385 0.867 | 0.485 0.024 0.048 | -0.459 0.032 0.043 | 10 | 3.367 | 1.564 0.222 0.216 | -0.868 0.077 0.067 | -2.310 0.806 0.471 | Variables Dim.1 ctr cos2 Dim.2 ctr cos2 Dim.3 ctr cos2 HPP | -0.894 46.500 0.799 | 0.178 2.056 0.032 | 0.148 2.122 0.022 | GPM | 0.417 10.104 0.174 | 0.099 0.638 0.010 | 0.870 73.208 0.758 | LG | -0.160 1.489 0.026 | 0.833 45.139 0.693 | -0.285 7.853 0.081 | AG | 0.842 41.218 0.709 | 0.185 2.223 0.034 | -0.356 12.240 0.127 | PM | 0.109 0.689 0.012 | 0.876 49.945 0.767 | 0.218 4.578 0.047 | #acp$ind$contrib colSums(acp$ind$contrib) Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 100 100 100 100 100 # acp$ind$cos2 # rowSums(acp$ind$cos2) # acp$ind$coord acp$var$contrib Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 HPP 46.5002070 2.0560761 2.121562 8.544112 40.7780426 GPM 10.1043069 0.6377917 73.207820 9.069750 6.9803323 LG 1.4889320 45.1390575 7.852844 44.729023 0.7901433 AG 41.2175394 2.2225611 12.239575 6.793278 37.5270458 PM 0.6890147 49.9445136 4.578199 30.863836 13.9244361 colSums(acp$var$contrib) Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 100 100 100 100 100 acp$var$cos2 Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 HPP 0.79947101 0.031574032 0.02195741 0.03779034 0.109207203 GPM 0.17372182 0.009794217 0.75767480 0.04011522 0.018693947 LG 0.02559898 0.693175734 0.08127413 0.19783508 0.002116074 AG 0.70864691 0.034130651 0.12667523 0.03004646 0.100500747 PM 0.01184613 0.766970487 0.04738273 0.13650979 0.037290871 rowSums(acp$var$cos2) HPP GPM LG AG PM 1 1 1 1 1 acp$var$coord Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 HPP -0.8941314 0.17769083 0.1481803 0.1943974 0.3304651 GPM 0.4167995 0.09896574 0.8704452 -0.2002878 0.1367258 LG -0.1599968 0.83257176 -0.2850862 -0.4447866 0.0460008 AG 0.8418117 0.18474483 -0.3559146 0.1733391 0.3170185 PM 0.1088399 0.87576851 0.2176757 0.3694723 -0.1931084 Forma 2 pca &lt;- ade4::dudi.pca(data.PCA, scannf = F, scale = T, nf = 5) pca Duality diagramm class: pca dudi $call: ade4::dudi.pca(df = data.PCA, scale = T, scannf = F, nf = 5) $nf: 5 axis-components saved $rank: 5 eigen values: 1.719 1.536 1.035 0.4423 0.2678 vector length mode content 1 $cw 5 numeric column weights 2 $lw 640 numeric row weights 3 $eig 5 numeric eigen values data.frame nrow ncol content 1 $tab 640 5 modified array 2 $li 640 5 row coordinates 3 $l1 640 5 row normed scores 4 $co 5 5 column coordinates 5 $c1 5 5 column normed scores other elements: cent norm # pca$l1 # scores normalizados # pca$li # scores pca$co # coordenadas de variables Comp1 Comp2 Comp3 Comp4 Comp5 HPP 0.8941314 0.17769083 0.1481803 -0.1943974 -0.3304651 GPM -0.4167995 0.09896574 0.8704452 0.2002878 -0.1367258 LG 0.1599968 0.83257176 -0.2850862 0.4447866 -0.0460008 AG -0.8418117 0.18474483 -0.3559146 -0.1733391 -0.3170185 PM -0.1088399 0.87576851 0.2176757 -0.3694723 0.1931084 # autovalores summary(pca) Class: pca dudi Call: ade4::dudi.pca(df = data.PCA, scale = T, scannf = F, nf = 5) Total inertia: 5 Eigenvalues: Ax1 Ax2 Ax3 Ax4 Ax5 1.7193 1.5356 1.0350 0.4423 0.2678 Projected inertia (%): Ax1 Ax2 Ax3 Ax4 Ax5 34.386 30.713 20.699 8.846 5.356 Cumulative projected inertia (%): Ax1 Ax1:2 Ax1:3 Ax1:4 Ax1:5 34.39 65.10 85.80 94.64 100.00 9.4.3 Gráfico de sedimentación # primera forma plot(pca$eig, type = &quot;b&quot;, pch = 20, col =&quot;blue&quot;) abline(h=1, lty = 3, col = &quot;red&quot;) fviz_eig(pca, geom = &quot;line&quot;)+ theme_test() # segunda forma eig.val &lt;- get_eigenvalue(pca) eig.val eigenvalue variance.percent cumulative.variance.percent Dim.1 1.7192848 34.385697 34.38570 Dim.2 1.5356451 30.712902 65.09860 Dim.3 1.0349643 20.699286 85.79789 Dim.4 0.4422969 8.845938 94.64382 Dim.5 0.2678088 5.356177 100.00000 9.4.4 Correlación entre variables y componentes pca$co Comp1 Comp2 Comp3 Comp4 Comp5 HPP 0.8941314 0.17769083 0.1481803 -0.1943974 -0.3304651 GPM -0.4167995 0.09896574 0.8704452 0.2002878 -0.1367258 LG 0.1599968 0.83257176 -0.2850862 0.4447866 -0.0460008 AG -0.8418117 0.18474483 -0.3559146 -0.1733391 -0.3170185 PM -0.1088399 0.87576851 0.2176757 -0.3694723 0.1931084 corpca &lt;- cbind(data.PCA,pca$li) i = cor(corpca, method=&quot;pearson&quot;) corrplot(i[1:5,6:10], sig.level = 0.05) 9.4.5 Gráfico de variables sobre el círculo de correlaciones fviz_pca_var(pca,repel = TRUE, axes = c(1,2)) fviz_pca_var(pca,repel = TRUE, axes = c(1,3)) 9.4.6 Gráfico de individuos sobre el primer plano de componentes fviz_pca_ind(pca,repel = TRUE,geom.ind = c(&quot;text&quot;,&quot;point&quot;),habillage = Tratamiento) Warning: ggrepel: 594 unlabeled data points (too many overlaps). Consider increasing max.overlaps 9.4.7 Gráfico de individuos sobre el primer plano con biplot fviz_pca_biplot(pca,repel = TRUE,habillage = Tratamiento) Warning: ggrepel: 600 unlabeled data points (too many overlaps). Consider increasing max.overlaps fviz_pca_biplot(pca,repel = TRUE,habillage = Tratamiento, addEllipses = T) Warning: ggrepel: 600 unlabeled data points (too many overlaps). Consider increasing max.overlaps "],["agradecimientos.html", "Chapter 10 Agradecimientos", " Chapter 10 Agradecimientos Un gran agradecimiento al Mg. Felipe de Mendiburu, por la creación del paquete agricolae y su excelente labor como docente en la Universidad Nacional Agraria La Molina. Mucho de este material ha sido creado gracias a su gran facilidad para explicar los métodos estadísticos aplicados a la agricultura. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
